# =============================================================================
# AI News Assistant - Centralized Configuration
# =============================================================================
#
# This is the single source of truth for all non-secret settings.
# 
# To find settings:
#   - Frontend behavior → frontend section
#   - AI models & processing → backend section  
#   - LLM prompts → prompts section
#   - Secrets (API keys) → backend/.env
#
# =============================================================================

# =============================================================================
# FRONTEND
# =============================================================================
frontend:
  # State persistence expiration in ms (24 hours)
  playbackStateExpirationMs: 86400000
  audioBar:
    # Show or hide manual Q&A mic button in the audio bar (demo mode can set false)
    showMicButton: false
  qa:
    # Delay in ms before resuming newsletter after Q&A answer ends
    resumeDelayMs: 1500
    # Maximum duration for recording a question (30 seconds)
    maxRecordingDurationMs: 30000

# =============================================================================
# VOICE MODE (shared frontend/backend)
# =============================================================================
voiceMode:
  model: "gemini-live-2.5-flash-native-audio"
  region: "us-central1"
  # Session timeout for client reconnection logic (14 minutes)
  sessionTimeoutMs: 840000
  # Client-side VAD sensitivity tuning (Silero VAD)
  vadSensitivity:
    positiveSpeechThreshold: 0.6
    negativeSpeechThreshold: 0.3
    minSpeechFrames: 4
  # Delay before resuming newsletter after voice Q&A
  resumeDelayMs: 1200
  # Buffer output at start of each turn to catch commands before audio leaks
  bufferGracePeriodMs: 300

# =============================================================================
# BACKEND
# =============================================================================
backend:
  processing:
    # Number of topic groups to process in parallel
    maxConcurrentSegments: 5
    # HTTP client timeout for fetching newsletters
    httpTimeoutSeconds: 30.0
    # Batch size for inserting segments into database
    segmentBatchSize: 50
    # Enable Chinese translation + audio generation
    enableChineseProcessing: false
    consolidation:
      # Discord consolidation mode:
      # - "off": keep all Discord sections
      # - "recap_only": keep only "AI Discord Recap", skip high-level + detailed Discord sections
      discordMode: "recap_only"
      # Remove repeated Reddit items using lightweight text fingerprint dedup
      redditLightDedup: true
    # RSS Feed URL for newsletter discovery
    rssUrl: "https://www.latent.space/feed?section=ainews"
  
  ai:
    models:
      # Model for cleaning newsletter text for TTS (needs high reasoning)
      # Gemini 3 Pro Preview requires global region, 
      # so currently set location="global" in code
      textCleaning: "gemini-3-flash-preview"
      # Model for Q&A (transcribe + answer) 
      qa: "gemini-2.5-flash-lite"
  
  tts:
    en:
      voiceName: "en-US-Chirp3-HD-Aoede"
      languageCode: "en-US"
    zh:
      voiceName: "cmn-CN-Chirp3-HD-Aoede"
      languageCode: "cmn-CN"
    speakingRate: 1.0

# =============================================================================
# PROMPTS
# =============================================================================
prompts:
  textCleaning: |
    Clean the following list of newsletter texts for text-to-speech.
    Return a JSON array of strings, where each string corresponds to the input text at the same index.

    Rules:
    1. Replace "@username" with "[username] tweeted"
    2. Replace "/r/subreddit" with "the [subreddit] subreddit"
    3. For markdown links [text](url), keep only the text
    4. If a text seems to be a header, keep it conversational (e.g. prefix with "Now:")
    5. Keep natural
    6. OUTPUT MUST BE A VALID JSON ARRAY OF STRINGS with exactly {count} elements.

    <texts_to_clean>
    {texts_json}
    </texts_to_clean>

  translation: |
    Translate the following list of English texts to Chinese (Simplified).
    Return a JSON array of strings, where each string corresponds to the input text at the same index.

    Rules:
    1. Preserve technical terms and proper nouns (keep them in English if commonly used that way, or translate with English in parentheses)
    2. Keep the translation natural and conversational for audio playback
    3. Maintain the same tone and style as the original
    4. Do not add or remove any content
    5. OUTPUT MUST BE A VALID JSON ARRAY OF STRINGS with exactly {count} elements.

    <texts_to_translate>
    {texts_json}
    </texts_to_translate>

  qaWithAudio:
    en: |
      You are an AI assistant helping a user listen to a newsletter.
      The user is listening to a newsletter with the following content:

      <content>
      {context}
      </content>

      The user asked a question via audio. First, transcribe what the user said, then answer their question based ONLY on the content above.

      Format your response as:
      TRANSCRIPT: [what the user said]
      ANSWER: [your answer to their question]

      Keep the answer conversational, concise, and suitable for audio playback (text-to-speech).
      Do not use markdown formatting like bold or lists, as it will be read aloud.
      If the answer is not in the content, say so politely.
      If the audio is silent or unintelligible, set TRANSCRIPT to '[unintelligible]' and ANSWER to a polite request for the user to repeat the question.
    zh: |
      你是一个帮助用户收听新闻简报的AI助手。
      用户正在收听以下内容的新闻简报：

      <content>
      {context}
      </content>

      用户通过语音提出了问题。首先，转录用户说的话，然后仅根据上述内容回答问题。

      请按以下格式回复：
      TRANSCRIPT: [用户说的话]
      ANSWER: [你的回答]

      回答要口语化、简洁，适合语音播放。
      不要使用markdown格式（如粗体或列表），因为内容将被朗读。
      如果答案不在内容中，请礼貌地说明。
      如果音频无声或无法识别，TRANSCRIPT设为'[无法识别]'，ANSWER设为礼貌地请求用户重复问题。

  voiceMode:
    en: |
      You are a voice assistant for a newsletter audio player.
      The ONLY tools you can call are: play, pause, next, previous, bookmark, rewind, forward.
      If the user's utterance is a control command for playback (including polite wrappers like "please play" or "can you pause"), ALWAYS call the matching tool and say nothing else.
      DO NOT response with "Let me check".
      If the utterance is not clearly one of those commands, treat it as a question and answer using ONLY the content below.
      If the answer is not in the content, say so politely.
      Keep the answer within 50 words.

      <newsletter>
      {context}
      </newsletter>
    zh: |
      你是新闻简报音频播放器的语音助手。
      你唯一可以调用的工具是：play, pause, next, previous, bookmark, rewind, forward。
      如果用户的话语是播放控制命令（包括礼貌用语如"请播放"或"暂停一下"），务必调用相应的工具，不要说任何其他内容。
      不要回复"让我查一下"之类的话。
      如果话语不是明确的命令，则将其视为问题，仅根据以下内容回答。
      如果答案不在内容中，请礼貌地说明。
      回答控制在50字以内。

      <newsletter>
      {context}
      </newsletter>
